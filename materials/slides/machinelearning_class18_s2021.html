<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Combining Human &amp; Machine Intelligence</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/lucy.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/middlebury-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="themes/class14-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Combining Human &amp; Machine Intelligence
## New Methods in Earth Observation
### Class 18

---


## Today
- Introduce Machine Learning (ML) and Deep Learning (DL) concepts
- Build your own classifier (Earth Engine)

---
class: center, middle
## Current Trends in EO

.center[![](figures/11/gc.jpg)]

---
- Earth Observations and Machine Learning on the Cloud for Improved Agricultural Decision Making
- Using Remote Sensing / Satellite Data for Human Disease Surveillance
- Estimating crop production at village level and mapping locally attainable yield gap from Sentinel time series using Sen2Agri in a smallholder farming system 
- Cost Effective Measurement of Soil Health Management Practices with Remote Sensing 
- Estimating impact and resilience via convolutional neural network-generated synthetic variables and remotely sensed imagery 
- Plantix - The agricultural app to empower family farms with the help of AI 
- Zoonotic prediction with machine learning 

---

- Getting the big picture right: integrating ground-based surveys and remote sensing for better data and insights
- Crowdsourcing real-time crop surveillance data from small-holder farmers
- e-Agri â€“ low cost sensing and communication systems to augment agricultural disease forecasting
- Nuru an AI system working with CGIAR, FAO and local extension to help smallholder farmers 
- Chameleon: a soil moisture sensor for smallholder farmers 
- A Cost-Effective Way of Collecting Crop Observations using Ultralight Aircraft - From SMS to Social Chat: How mobile messaging can support crop surveillance and audience engagement in Africa 

---
  
## Heavy emphasis on "ground-truth"

- [Plant Village](https://plantvillage.psu.edu/solutions)

---
background-image: url(figures/11/nuru.jpg)
background-size: 60%

---

- [GeoSurvey](https://qed.ai/geosurvey-collect/)
  - [GeoSurvey - cheap spectroscopy](https://qed.ai/scanspectrum/)

---
## Combining Human &amp; Machine Intelligence

.center[![](figures/11/ml-pipe.png)]
.center[An increasingly typical data science workflow]

---

## Background
- Algorithms of increasing complexity + predictive power
- Machine learning
  - [Definition](https://en.wikipedia.org/wiki/Machine_learning): 
      - Ability to progressively improve predictions without explicit programming
  - Characteristics:
      - Non-parametric
      - Can predict complex classes
      - Can handle highly dimensioned data
      - More effective than traditional classifiers

---
background-image: url(https://cdn-images-1.medium.com/max/1600/1*xGsYc6aXehD7lyoLEn-mMA.png)
background-size: 50%
background-position: bottom

## Classes of algorithms

Check out this [nice overview](https://www.dropbox.com/s/y7boyxe4ao2fppo/Computer%20Vision%20Machine%20Learning%20Deep%20Learning.pdf?dl=0) by Luisa Young and Lei Song from GEOG391

### Decision trees

- Simple or ensemble (random forest)

---
background-image: url(https://docs.opencv.org/2.4/_images/separating-lines.png)
background-size: 50%
background-position: bottom

### Support Vector Machines
- Optimal plane separating two classes

---
background-image: url(https://cdn-images-1.medium.com/max/2000/1*bhFifratH9DjKqMBTeQG5A.gif)
background-size: 50%
background-position: bottom

### Neural networks
- Mimics structure of animals brains
- Artificial neurons connected by "edges" (synapses)
- Hidden layers determine how inputs mapped to outputs
- One output neuron (node) per class

---
## Machine learning and training data

- Need large amounts of training data
- Typically human interpretation of imagery

---
background-image: url(figures/11/ml_td_needs.png)


---
background-image: url(figures/11/cropland-org.png)
background-size: 50%
background-position: bottom

## Examples
- croplands.org (Xiong et al, 2017)

---
background-image: url(figures/11/croplands-workflow.png)
background-size: 75%

---
background-image: url(figures/11/footprints.png)
background-size: 60%
background-position: center

## Examples
- Microsoft [building footprints](https://www.arcgis.com/home/webmap/viewer.html?useExisting=1&amp;layers=f40326b0dea54330ae39584012807126)

---
## Potential Problems with machine learning

![](figures/11/problem1.png)

---
## Potential Problems with machine learning

![](figures/11/problem2.png)
- [Elon Musk interview](https://www.youtube.com/watch?v=H15uuDMqDK0 )

---
## Importance of Training Data

![](figures/11/remotesensing_title.png)

- [Elmes et al. (2020)](https://doi.org/10.3390/rs12061034)


---
## Importance of Training Data
- Harmonize terminology
- Locate TD practices in context with accepted accuracy assessment methods
- Sources of error/uncertainty in TD 
- How to minimize and measure those errors
- How to quantify error impact on maps
- Proposes three tiers of accounting standards

---
background-image: url(https://www.mdpi.com/remotesensing/remotesensing-12-01034/article_deploy/html/images/remotesensing-12-01034-g006.png)
background-size: 70%
background-position: center

---
background-image: url(figures/11/al_slides.002.png)
background-size: 70%
background-position: bottom

# Our solution
[Lyndon's Presentation](https://www.youtube.com/watch?v=pCp7SoNDHfE&amp;list=PL3QzFgBMGnbQRa8uHP0_C_P2Fl5GIBxmn&amp;index=2&amp;t=2224s)

---
## ML in Earth Engine 
- [Noel Gorelick presentation](https://docs.google.com/presentation/d/1BFZVhUVKiANHvSi5ApbmjPqiOEHNBV_NizDVzJJ05tI/htmlpresent)

---
## ML in Earth Engine 
- Steps
 - (1) Collect observations (min: 25-30 per class)
 - (2) Separate observations into training and validation data
 - (3) Build model
 - (4) Train model with training data
 - (5) Apply model to broader area
 - (6) Evaluate model on training/validation


---
## Demo
- Based on [this tutorial](https://geohackweek.github.io/GoogleEarthEngine/05-classify-imagery/)
- We will be using random forests 
 - [video](https://www.youtube.com/watch?v=cIbj0WuK41w)


---
## Demo
- Setup

```js
// Define a region of interest as a point.  Change the coordinates
// to get a classification of any place where there is imagery.
Map.setOptions('HYBRID');
var lon = -71.8065
var lat = 42.1218
var roi = ee.Geometry.Point(lon, lat);
Map.setCenter(lon, lat, 12)

// Load the Landsat 8 scaled radiance image collection.
var landsatCollection = ee.ImageCollection('LANDSAT/LC08/C01/T1')
    .filterDate('2019-06-20', '2019-08-31').filterBounds(roi);
print(landsatCollection)

// Make a cloud-free composite.
var composite = ee.Algorithms.Landsat.simpleComposite({
  collection: landsatCollection,
  asFloat: true
});
print('composite', composite)
// Visualize the Composite
Map.addLayer(composite, {bands: ['B4', 'B3', 'B2'], max: 0.5, gamma: 2}, 'L8 Image', false);
```

---
## Demo
- (1) Collect training data
 - Use the point marker (in the map) to create a new point layer
 - Add ~30 points over water bodies
 - When finished, click on the gear icon next to the point layer ('geometry')
  - Rename layer to "water_sutton"
  - Import as "Feature Collection"
  - Add a property, "landcover", with value 0
  - Click OK, then Exit

---
## Demo
- (1) Collect training data
 - In the map, below "water_sutton", click "+new layer"
 - Add new layers for urban, forest, and crops
 - Add "landcover" property with vales (1), (2), (3), respectively


---
## Demo
- (1) Collect training data
 - In the map, below "water_sutton", click "+new layer"
 - Add new layers for urban, forest, and crops
 - Add "landcover" property with vales (1), (2), (3), respectively


---
- (1) Collect training data
 - Merge training data sets
 - Sample composite image at training sites

```js
// Merge the geometry layers into a single FeatureCollection.
var newfc = water_sutton.merge(urban_sutton).merge(forest_sutton).merge(crop_sutton);
print('newfc', newfc)

// Select the bands for training
var bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7'];

// Sample the input imagery to get a FeatureCollection of training data.
var data = composite.select(bands).sampleRegions({
  collection: newfc, 
  properties: ['landcover'], 
  scale: 30
});
print('data', data)
```


---
## Demo
- (2) Separate training/validation data


```js
// add a random column (by default named 'random')
data = data.randomColumn();
// split in a training (80%) and validation (20%)
var training = data.filter(ee.Filter.gt('random',0.2));
var validation = data.filter(ee.Filter.lte('random',0.2));

print('validation', validation);
print('training', training);
```

---
## Demo
- (3/4) Make a random forest classifier and train it


```js
// Make a Random Forest classifier and train it.
var classifier = ee.Classifier.smileRandomForest({numberOfTrees: 1000, seed: 0}).train({
  features: training, 
  classProperty: 'landcover', 
  inputProperties: bands
});

classifier.setOutputMode("CLASSIFICATION")
```


---
## Demo
- (5) Apply classifier to broader area


```js
var classified = composite.select(bands).classify(classifier);

// Define a palette for the Land Use classification.
var palette = [
  '0000FF', // water (0)  // blue
  'D3D3D3', // urban (1)  // grey
  '008000', //  forest (2) // green
  '#ffff00' // crop (3) // yellow
];

// Display the classification result and the input image.
//Map.setCenter(-96.0171, 29.6803);
Map.addLayer(classified, {min: 0, max: 3, palette: palette}, 'Land Use Classification');

```

---
## Demo
- (6) Evaluate model on training/validation


```js
// Get a confusion matrix representing resubstitution accuracy.
print('Training error matrix: ', classifier.confusionMatrix());
print('Training accuracy: ', classifier.confusionMatrix().accuracy());

//// Test on validation data set .

// Classify the test FeatureCollection.
var test = validation.classify(classifier);
print('test', test)

var confusionMatrix = test.errorMatrix('landcover', 'classification');
print('Validation error matrix', confusionMatrix);
print('Validation testing accuraccy', confusionMatrix.accuracy());

```

---
## Demo
- Error matrices
 - Rows represent actual values 
 - Columns represent predicted values




---
## Demo 



---
## Demo
- Test additional classifiers


```js
// add the code below just after the initial definition for "classifier"

// var classifier = ee.Classifier.libsvm().train({
//   features: training, 
//   classProperty: 'landcover', 
//   inputProperties: bands
// });

// var classifier = ee.Classifier.minimumDistance().train({
//   features: training, 
//   classProperty: 'landcover', 
//   inputProperties: bands
// });

// var classifier = ee.Classifier.smileCart().train({
//   features: training, 
//   classProperty: 'landcover', 
//   inputProperties: bands
// });

// var classifier = ee.Classifier.smileGradientTreeBoost({numberOfTrees: 100}).train({
//   features: training, 
//   classProperty: 'landcover', 
//   inputProperties: bands
// });
```

---
### Neural Networks video
- Neural networks (NN) form the basis for deep learning
- [Video](https://www.youtube.com/watch?v=aircAruvnKk) (20 mins)



---
## For next class
- Work on Assignment 3 (due Thursday 11:59 PM)
- Watch [video on neural network cost function](https://www.youtube.com/watch?v=IHZwWFHWa-w)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
